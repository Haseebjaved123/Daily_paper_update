# 📅 Date: 2025-09-02

## 📄 Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation

### 👥 Authors
Tobias Hyrup, Emmanouil Panagiotou, Arjun Roy, Arthur Zimek, Eirini Ntoutsi, Peter Schneider-Kamp

### 🔗 Links
- **Primary**: [2508.21815v1](https://arxiv.org/abs/2508.21815v1)
- **PDF**: [Download PDF](https://arxiv.org/pdf/2508.21815v1.pdf) *(if available)*



### 🏷️ Classification
- **Primary Domain**: ML
- **Categories**: ML
- **Complexity**: Medium
- **Source**: Arxiv

### 📊 Paper Statistics
- **Word Count**: 215 words
- **Sentences**: 8 sentences
- **Authors**: 6 researchers

### 🔍 Key Topics
Transformers

### 🛠️ Methodologies
Dataset Creation

### 🖼️ Figure
![No Figure Available](https://img.shields.io/badge/Figure-Not_Available-lightgrey?style=for-the-badge)

### 📝 Abstract
As privacy regulations such as the GDPR and HIPAA and responsibility frameworks for artificial intelligence such as the AI Act gain traction, the ethical and responsible use of real-world data faces increasing constraints. Synthetic data generation has emerged as a promising solution to risk-aware data sharing and model development, particularly for tabular datasets that are foundational to sensitive domains such as healthcare. To address both privacy and fairness concerns in this setting, we propose FLIP (Fair Latent Intervention under Privacy guarantees), a transformer-based variational autoencoder augmented with latent diffusion to generate heterogeneous tabular data. Unlike the typical setup in fairness-aware data generation, we assume a task-agnostic setup, not reliant on a fixed, defined downstream task, thus offering broader applicability. To ensure privacy, FLIP employs R\'enyi differential privacy (RDP) constraints during training and addresses fairness in the input space with RDP-compatible balanced sampling that accounts for group-specific noise levels across multiple sampling rates. In the latent space, we promote fairness by aligning neuron activation patterns across protected groups using Centered Kernel Alignment (CKA), a similarity measure extending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment encourages statistical independence between latent representations and the protected feature. Empirical results demonstrate that FLIP effectively provides significant fairness improvements for task-agnostic fairness and across diverse downstream tasks under differential privacy constraints.

---
*Generated by Advanced Paper Update System - Multi-Source Intelligence*
